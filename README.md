# ğŸ§  Alzheimer HastalÄ±ÄŸÄ± TeÅŸhisi - Derin Ã–ÄŸrenme Projesi

Bu proje, Alzheimer hastalÄ±ÄŸÄ±nÄ±n erken teÅŸhisi iÃ§in Ã§eÅŸitli derin Ã¶ÄŸrenme modellerini kullanarak beyin MRI gÃ¶rÃ¼ntÃ¼lerini analiz eden kapsamlÄ± bir Ã§alÄ±ÅŸmadÄ±r.

## ğŸ“‹ Proje Ã–zeti

Alzheimer hastalÄ±ÄŸÄ±, demansÄ±n en yaygÄ±n tÃ¼rÃ¼dÃ¼r ve erken teÅŸhis bÃ¼yÃ¼k Ã¶nem taÅŸÄ±r. Bu proje, beyin MRI gÃ¶rÃ¼ntÃ¼lerini analiz ederek Alzheimer hastalÄ±ÄŸÄ±nÄ±n farklÄ± aÅŸamalarÄ±nÄ± (NonDemented, VeryMildDemented, MildDemented, ModerateDemented) sÄ±nÄ±flandÄ±rmak iÃ§in Ã§eÅŸitli derin Ã¶ÄŸrenme modellerini test eder.

## ğŸ¯ Hedefler

- Alzheimer hastalÄ±ÄŸÄ±nÄ±n 4 farklÄ± aÅŸamasÄ±nÄ± sÄ±nÄ±flandÄ±rma
- FarklÄ± derin Ã¶ÄŸrenme mimarilerinin performansÄ±nÄ± karÅŸÄ±laÅŸtÄ±rma
- Transfer Ã¶ÄŸrenme tekniklerini kullanarak model performansÄ±nÄ± optimize etme
- Ã‡eÅŸitli optimizasyon algoritmalarÄ±nÄ±n etkisini analiz etme

## ğŸ—ï¸ KullanÄ±lan Modeller

### 1. **CNN (Convolutional Neural Network)**
- **Dosya**: `cnn.py`
- **Veri Seti**: Orijinal dataset (70-30 split)
- **GÃ¶rÃ¼ntÃ¼ FormatÄ±**: Grayscale (1 kanal)
- **Ã–zellikler**:
  - FarklÄ± nÃ¶ron konfigÃ¼rasyonlarÄ± test edildi: (32,32), (64,64), (32,32,32,32), (32,32,64,64), (64,64,64,64)
  - 6 farklÄ± optimizasyon algoritmasÄ± karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±: Adam, RMSprop, SGD, Adagrad, Adadelta, Nadam
  - Early stopping ve learning rate reduction kullanÄ±ldÄ±
  - Dropout katmanlarÄ± ile overfitting Ã¶nlendi

### 2. **DenseNet121**
- **Dosya**: `densenet121.py`
- **Veri Seti**: 50% Augmented 20% Split Dataset
- **GÃ¶rÃ¼ntÃ¼ FormatÄ±**: RGB (3 kanal)
- **Ã–zellikler**:
  - Transfer Ã¶ÄŸrenme ile ImageNet aÄŸÄ±rlÄ±klarÄ± kullanÄ±ldÄ±
  - Global Average Pooling ve Batch Normalization
  - 6 farklÄ± optimizasyon algoritmasÄ± test edildi
  - Dropout rate: 0.5

### 3. **EfficientNetB0**
- **Dosya**: `efficientnetb0.py`
- **Veri Seti**: Orijinal dataset (80-20 split)
- **GÃ¶rÃ¼ntÃ¼ FormatÄ±**: RGB (3 kanal)
- **Ã–zellikler**:
  - Son 30 katman fine-tuning
  - Cosine Annealing Learning Rate Scheduler
  - SÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ± ile dengesiz veri seti yÃ¶netimi
  - ModerateDemented sÄ±nÄ±fÄ± iÃ§in 10x aÄŸÄ±rlÄ±k artÄ±rÄ±mÄ±
  - Dropout rate: 0.2

### 4. **MobileNetV2**
- **Dosya**: `mobilenetv2.py`
- **Veri Seti**: 50% Augmented 20% Split Dataset
- **GÃ¶rÃ¼ntÃ¼ FormatÄ±**: RGB (3 kanal)
- **Ã–zellikler**:
  - Hafif ve mobil uyumlu mimari
  - Transfer Ã¶ÄŸrenme ile optimize edilmiÅŸ performans
  - 6 farklÄ± optimizasyon algoritmasÄ± karÅŸÄ±laÅŸtÄ±rmasÄ±
  - Dropout rate: 0.5
  - Dense katmanÄ±nda 256 nÃ¶ron

### 5. **ResNet50**
- **Dosya**: `resnet50.py`
- **Veri Seti**: Orijinal dataset (80-20 split)
- **GÃ¶rÃ¼ntÃ¼ FormatÄ±**: RGB (3 kanal)
- **Ã–zellikler**:
  - Son 20 katman fine-tuning
  - Cosine Annealing Learning Rate Scheduler
  - ModerateDemented sÄ±nÄ±fÄ± iÃ§in 25x aÄŸÄ±rlÄ±k artÄ±rÄ±mÄ±
  - Dropout rate: 0.5
  - Batch size: 4 (dÃ¼ÅŸÃ¼k batch size)

### 6. **VGG16**
- **Dosya**: `vgg16.py`
- **Veri Seti**: Dataset 220 Split Dataset
- **GÃ¶rÃ¼ntÃ¼ FormatÄ±**: RGB (3 kanal)
- **Ã–zellikler**:
  - Klasik VGG mimarisi
  - Transfer Ã¶ÄŸrenme ile ImageNet aÄŸÄ±rlÄ±klarÄ±
  - 6 farklÄ± optimizasyon algoritmasÄ± test edildi
  - Dropout rate: 0.3
  - Dense katmanÄ±nda 128 nÃ¶ron

### 7. **VGG19**
- **Dosya**: `vgg19.py`
- **Veri Seti**: Same Augmented 20% Split Dataset
- **GÃ¶rÃ¼ntÃ¼ FormatÄ±**: RGB (3 kanal)
- **Ã–zellikler**:
  - VGG16'ya gÃ¶re daha derin mimari
  - Transfer Ã¶ÄŸrenme ile optimize edilmiÅŸ performans
  - 6 farklÄ± optimizasyon algoritmasÄ± karÅŸÄ±laÅŸtÄ±rmasÄ±
  - Dropout rate: 0.5
  - Dense katmanÄ±nda 128 nÃ¶ron

## ğŸ“Š Veri Seti

Proje, Alzheimer hastalÄ±ÄŸÄ±nÄ±n 4 farklÄ± aÅŸamasÄ±nÄ± iÃ§eren beyin MRI gÃ¶rÃ¼ntÃ¼lerini kullanÄ±r:

- **NonDemented**: Demans olmayan
- **VeryMildDemented**: Ã‡ok hafif demans
- **MildDemented**: Hafif demans
- **ModerateDemented**: Orta demans

### Veri Seti Ã–zellikleri:
- **GÃ¶rÃ¼ntÃ¼ Boyutu**: 224x224 piksel
- **Renk KanalÄ±**: RGB (3 kanal) ve Grayscale (1 kanal)
- **Veri ArtÄ±rma**: BazÄ± modellerde data augmentation kullanÄ±ldÄ±
- **Split OranlarÄ±**: 70-30, 80-20, 50% Augmented gibi farklÄ± konfigÃ¼rasyonlar

## ğŸ”§ Teknik Ã–zellikler

### KullanÄ±lan KÃ¼tÃ¼phaneler:
- **TensorFlow/Keras**: Derin Ã¶ÄŸrenme modelleri
- **NumPy**: SayÄ±sal iÅŸlemler
- **PIL**: GÃ¶rÃ¼ntÃ¼ iÅŸleme
- **Matplotlib/Seaborn**: GÃ¶rselleÅŸtirme
- **Scikit-learn**: Metrikler ve veri bÃ¶lme
- **Google Colab**: Ã‡alÄ±ÅŸma ortamÄ±

### Optimizasyon AlgoritmalarÄ±:
- **Adam**: Learning rate 0.001 (CNN, DenseNet, VGG16, VGG19), 0.0001 (EfficientNet, ResNet), 0.0005 (MobileNet)
- **SGD**: Learning rate 0.01 (CNN, DenseNet, VGG16, VGG19), 0.00005 (EfficientNet, ResNet), 0.005 (MobileNet)
- **Nadam**: Learning rate 0.002 (CNN, DenseNet, VGG16, VGG19), 0.0001 (EfficientNet, ResNet), 0.001 (MobileNet)
- **RMSprop**: Learning rate 0.001 (CNN, DenseNet, VGG16, VGG19), 0.0001 (EfficientNet, ResNet), 0.0005 (MobileNet)
- **Adadelta**: Learning rate 1.0 (CNN, DenseNet, VGG16, VGG19), 1.0 (EfficientNet, ResNet), 0.5 (MobileNet)
- **Adagrad**: Learning rate 0.01 (CNN, DenseNet, VGG16, VGG19), 0.001 (EfficientNet, ResNet), 0.005 (MobileNet)

### DeÄŸerlendirme Metrikleri:
- **Accuracy (DoÄŸruluk)**: Test seti Ã¼zerinde doÄŸru tahmin oranÄ±
- **F1 Score (AÄŸÄ±rlÄ±klÄ± ortalama)**: Precision ve Recall'Ä±n harmonik ortalamasÄ±
- **Recall Score (AÄŸÄ±rlÄ±klÄ± ortalama)**: GerÃ§ek pozitiflerin doÄŸru tahmin edilme oranÄ±
- **Confusion Matrix**: SÄ±nÄ±f bazÄ±nda karÄ±ÅŸÄ±klÄ±k matrisi
- **Classification Report**: DetaylÄ± sÄ±nÄ±f bazÄ±nda performans raporu

## ğŸš€ Kurulum ve KullanÄ±m

### Gereksinimler:
```bash
pip install tensorflow
pip install numpy
pip install pillow
pip install matplotlib
pip install seaborn
pip install scikit-learn
```

### Ã‡alÄ±ÅŸtÄ±rma:
Her model dosyasÄ±nÄ± ayrÄ± ayrÄ± Ã§alÄ±ÅŸtÄ±rabilirsiniz:

```bash
python cnn.py
python densenet121.py
python efficientnetb0.py
python mobilenetv2.py
python resnet50.py
python vgg16.py
python vgg19.py
```

## ğŸ“ˆ SonuÃ§lar

Her model iÃ§in aÅŸaÄŸÄ±daki analizler yapÄ±lmÄ±ÅŸtÄ±r:

1. **Model PerformansÄ±**: Test accuracy, F1 score, recall deÄŸerleri
2. **Optimizasyon KarÅŸÄ±laÅŸtÄ±rmasÄ±**: 6 farklÄ± optimizasyon algoritmasÄ±nÄ±n performansÄ±
3. **GÃ¶rselleÅŸtirme**: 
   - Confusion Matrix
   - Loss ve Accuracy grafikleri
   - Model mimarisi diyagramlarÄ±
4. **DetaylÄ± Raporlar**: Classification report ile sÄ±nÄ±f bazÄ±nda performans

## ğŸ“ Proje YapÄ±sÄ±

```
Deep-Learning---Alzheimer-Disease/
â”œâ”€â”€ cnn.py                 # CNN modeli (Grayscale, 70-30 split)
â”œâ”€â”€ densenet121.py         # DenseNet121 modeli (RGB, Augmented dataset)
â”œâ”€â”€ efficientnetb0.py      # EfficientNetB0 modeli (RGB, 80-20 split)
â”œâ”€â”€ mobilenetv2.py         # MobileNetV2 modeli (RGB, Augmented dataset)
â”œâ”€â”€ resnet50.py            # ResNet50 modeli (RGB, 80-20 split)
â”œâ”€â”€ vgg16.py               # VGG16 modeli (RGB, 220 split dataset)
â”œâ”€â”€ vgg19.py               # VGG19 modeli (RGB, Augmented dataset)
â”œâ”€â”€ requirements.txt        # Gerekli Python kÃ¼tÃ¼phaneleri
â”œâ”€â”€ README.md              # Proje dokÃ¼mantasyonu
â””â”€â”€ bitirme.pdf            # Bitirme tezi
```

## ğŸ”§ Model KonfigÃ¼rasyonlarÄ±

### CNN Modeli:
- **GiriÅŸ**: 224x224x1 (Grayscale)
- **KonvolÃ¼syon KatmanlarÄ±**: FarklÄ± nÃ¶ron sayÄ±larÄ± test edildi
- **Dropout**: 0.2, 0.25, 0.3 oranlarÄ±nda
- **Dense KatmanlarÄ±**: 100 ve 50 nÃ¶ron

### Transfer Learning Modelleri:
- **Base Model**: ImageNet aÄŸÄ±rlÄ±klarÄ± ile Ã¶nceden eÄŸitilmiÅŸ
- **Fine-tuning**: EfficientNet (son 30 katman), ResNet (son 20 katman)
- **Global Average Pooling**: Ã–zellik Ã§Ä±karÄ±mÄ± iÃ§in
- **Batch Normalization**: EÄŸitim stabilizasyonu iÃ§in
- **Dropout**: Overfitting Ã¶nleme iÃ§in
- **Dense KatmanlarÄ±**: 128-256 nÃ¶ron arasÄ±

## ğŸ” Ã–nemli Bulgular

- **Transfer Ã–ÄŸrenme**: ImageNet aÄŸÄ±rlÄ±klarÄ± ile eÄŸitilen modeller daha iyi performans gÃ¶sterdi
- **Optimizasyon**: Adam ve Nadam optimizasyonlarÄ± genellikle en iyi sonuÃ§larÄ± verdi
- **Veri ArtÄ±rma**: Augmented veri setleri model performansÄ±nÄ± artÄ±rdÄ±
- **SÄ±nÄ±f DengesizliÄŸi**: ModerateDemented sÄ±nÄ±fÄ± iÃ§in Ã¶zel aÄŸÄ±rlÄ±k artÄ±rÄ±mÄ± gerekli
- **Fine-tuning**: EfficientNet ve ResNet modellerinde son katmanlarÄ±n eÄŸitilebilir yapÄ±lmasÄ± performansÄ± artÄ±rdÄ±
- **Cosine Annealing**: SGD optimizasyonu ile birlikte kullanÄ±lan cosine annealing scheduler daha stabil eÄŸitim saÄŸladÄ±
- **Batch Size**: ResNet50'de dÃ¼ÅŸÃ¼k batch size (4) kullanÄ±lmasÄ± memory optimizasyonu saÄŸladÄ±
- **Dropout**: FarklÄ± modellerde farklÄ± dropout oranlarÄ± (0.2-0.5) kullanÄ±larak overfitting Ã¶nlendi

## ğŸ“ Lisans

Bu proje eÄŸitim ve araÅŸtÄ±rma amaÃ§lÄ± geliÅŸtirilmiÅŸtir.

## ğŸ‘¨â€ğŸ’» GeliÅŸtirici

Bu proje, Alzheimer hastalÄ±ÄŸÄ± teÅŸhisi iÃ§in derin Ã¶ÄŸrenme tekniklerini araÅŸtÄ±rmak ve karÅŸÄ±laÅŸtÄ±rmak amacÄ±yla geliÅŸtirilmiÅŸtir.

## ğŸ¤ KatkÄ±da Bulunma

Projeye katkÄ±da bulunmak iÃ§in:
1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/AmazingFeature`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -m 'Add some AmazingFeature'`)
4. Branch'inizi push edin (`git push origin feature/AmazingFeature`)
5. Pull Request oluÅŸturun

## ğŸ“ Ä°letiÅŸim

SorularÄ±nÄ±z iÃ§in GitHub Ã¼zerinden issue aÃ§abilirsiniz.

---

**Not**: Bu proje eÄŸitim amaÃ§lÄ±dÄ±r ve tÄ±bbi teÅŸhis iÃ§in kullanÄ±lmamalÄ±dÄ±r. GerÃ§ek tÄ±bbi uygulamalar iÃ§in uzman doktorlarÄ±n deÄŸerlendirmesi gereklidir. 